# Emerobalize: 基于LLM的应急决策模拟器

**Emerobalize** 是一个结合了大型语言模型 (LLM) 与复杂AI行为模拟的2D应急疏散场景模拟器。本项目旨在探索在紧急情况下，个体与群体的决策如何受到认知、社会及环境因素的影响。它不仅仅是一个游戏，更是一个用于验证心理学和社会学理论的交互式实验平台。

![游戏截图示例](https://placehold.co/600x400/000000/FFFFFF?text=游戏运行截图)

---

## 核心特色

* **动态事件生成**: 利用 Google Gemini Pro 模型，游戏中的部分关键决策事件（如与NPC的交互、探索特定地点）是动态生成的，为玩家提供独一无二的体验。
* **复杂群体AI**: NPC不再是简单的“僵尸”，它们会基于压力、从众心理、权威效应、群体认同和责任分散等多种理论模型做出决策。
* **深度理论整合**: 游戏的核心机制深度融合了四大社会科学理论，力求在虚拟环境中重现真实的个体与群体动态。
* **沉浸式压力模拟**: 通过视觉效果（隧道视野、屏幕晃动）和操控影响（操作失误）来直观地模拟玩家在压力下的认知负担。

---

## 理论整合审查清单 (Integration Checklist)

本项目的设计与开发严格遵循一个理论整合框架。以下是根据代码 (`emerobalize_pygame.py`) 实现的详细分析：

### 一、认知处理理论 (Cognitive Processing Theory)
*认知处理 = 认知容量 × 处理模式 × 压力影响 × 学习效应*

**整合度评估：约 70%**

| 组件 | 状态 | 实现方式 |
| :--- | :--- | :--- |
| **压力影响** | [✓] 已实现 | `player.state['stress']` 变量是游戏的核心。它通过视觉效果 (`draw_vignette` 隧道视野, `shake_intensity` 屏幕晃动) 和操控 (`CONTROL_IMPAIR_CHANCE` 操作失误概率) 直接影响玩家。|
| **认知容量** | [✓] 已实现 | 引入 `player.state['focus']` (专注点数) 变量。每次玩家做出决策时都会消耗 (`process_choice` 函数)，这个“心力值”被直接用作LLM生成决策选项的上下文，模拟了认知负荷。 |
| **处理模式** | [~] 部分实现 | LLM的Prompt中已加入根据不同“措辞框架” (`framing_mode`) 来改变选项风格的指令，如“损失规避”或“收益寻求”，这是对决策处理模式的初步模拟。 |
| **学习效应** | [✗] 尚未实现 | 游戏目前是“一局一结”的，没有记忆。无法模拟玩家因重复失败而产生的“习得性无助”，或因成功而积累的“经验/自信”。 |

### 二、社会影响理论 (Social Influence Theory)
*社会影响 = 群体压力 × 权威效应 × 责任分散 × 身份认同*

**整合度评估：100%**

| 组件 | 状态 | 实现方式 |
| :--- | :--- | :--- |
| **群体压力** | [✓] 已实现 | 在 `Agent.get_conformity_behavior` 方法中，当周围大多数NPC (`visible_agents`) 都在逃跑时，未决定的NPC自己也会进入`flee`状态，模拟了从众行为。 |
| **权威效应** | [✓] 已实现 | `leadership_score` 系统让玩家或高分NPC成为“权威”。高压下的NPC (`AGENT_STRESS_THRESHOLD_FOLLOW`) 会主动调用 `find_leader` 函数，跟随这个权威。 |
| **责任分散** | [✓] 已实现 | `medic` (医生) NPC在决定是否救助伤员前，会检查周围的“旁观者” (`bystanders`) 数量，旁观者越多，它“出手”的概率 (`1.0 / (1 + bystanders * 0.5)`) 就越低。 |
| **身份认同** | [✓] 已实现 | NPC拥有 `group_id`。这个身份标识会影响其行为优先级，例如医生会优先救助“自己人” (`find_injured_agent` 中的排序逻辑)，NPC也更倾向于跟随同组的领袖 (`find_leader` 中的分数加成)。 |

### 三、群体动力学理论 (Group Dynamics Theory)
*群体动力学 = 物理约束 × 心理传染 × 空间效应 × 流动阻力*

**整合度评估：约 80%**

| 组件 | 状态 | 实现方式 |
| :--- | :--- | :--- |
| **物理约束** | [✓] 已实现 | 通过全局的 `occupied_tiles` 集合，我们实现了实体（玩家和NPC）的碰撞检测，它们不能占据同一个格子。 |
| **心理传染** | [✓] 已实现 | 一个`flee`状态的NPC会像一个“恐慌信标”，通过 `PANIC_SPREAD_RADIUS` 和 `PANIC_SPREAD_STRENGTH` 增加其周围其他NPC的压力值，实现了情绪在空间中的传播。 |
| **流动阻力** | [✓] 已实现 | 这是“物理约束”带来的自然**涌现**结果。在狭窄的门口或走廊，由于NPC无法重叠，真实的拥堵和排队现象会自动发生。 |
| **空间效应** | [✗] 尚未实现 | 我们还没有模拟“当个体淹没在人群中时，责任感和个性会降低”的去个性化现象。 |

### 四、决策行为理论 (Decision Behavior Theory)
*决策行为 = 风险感知 × 价值权衡 × 文化滤镜 × 情境适应*

**整合度评估：约 50%**

| 组件 | 状态 | 实现方式 |
| :--- | :--- | :--- |
| **风险感知** | [✓] 已实现 | 通过LLM的Prompt工程，在与地图对象交互时，系统会随机选择 `'loss_aversion'` (损失规避) 或 `'gain_seeking'` (收益寻求) 的措辞框架，动态生成不同“说法”的选项，以测试玩家的决策偏好。 |
| **价值权衡** | [~] 隐式实现 | 游戏中的选择（如“救人还是拿钥匙”）本身就是一种价值权衡，但它更多地体现在 `process_choice` 的硬编码结果中，而非一个明确的动态系统。 |
| **文化滤镜** | [✗] 尚未实现 | NPC尚无“个人主义”或“集体主义”等更深层的文化价值观属性来影响其行为权重。 |
| **情境适应** | [✗] 尚未实现 | 玩家的领导力收益是固定的，尚未实现根据人群的“状态”（如混乱/有序）来动态调整不同决策的奖惩。 |

---

## 如何运行

### 1. 环境配置

你需要安装 Python 和 Pygame。

```bash
# 安装依赖
pip install pygame
pip install google-generativeai
```

### 2. 设置API密钥

为了使用LLM驱动的动态事件，你需要一个 Google AI API 密钥。

1.  访问 [Google AI Studio](https://aistudio.google.com/) 获取你的 API 密钥。
2.  打开 `emerobalize_pygame.py` 文件。
3.  找到以下这行代码：
    ```python
    genai.configure(api_key="YOUR_API_KEY") 
    ```
4.  将 `"YOUR_API_KEY"` 替换为你自己的密钥。

### 3. 运行游戏

```bash
python emerobalize_pygame.py
```

---

## 未来方向

根据理论整合清单，以下是未来可以探索和实现的功能：

* **[ ] 学习效应**: 开发一个元系统，用于保存和加载玩家的关键数据，以模拟长期学习和习得性无助。
* **[ ] 空间效应**: 增加一个机制，使NPC在人群密度极高时，其个体行为（如医生的利他行为）的优先级会降低。
* **[ ] 文化滤镜**: 为NPC引入更深层次的性格或文化属性，使其决策权重更加多样化。
* **[ ] 情境适应**: 使决策的收益（如领导力点数）根据当前场景的紧急或有序程度动态变化。
